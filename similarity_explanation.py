"""
相似度分数计算的详细技术实现说明

=============================================================================
完整工作流程和代码对应关系
=============================================================================
"""

ARCHITECTURE = """
┌─────────────────────────────────────────────────────────────────┐
│                    RAG 系统中的相似度计算                          │
└─────────────────────────────────────────────────────────────────┘

【原文档索引阶段】(在 index_documents.py 中)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

   PDF 文档
      ↓
   [PyPDFLoader] 加载文档
      ↓
   [RecursiveCharacterTextSplitter] 分割成 512 字符的块
      ↓
   ┌──────────────────────────────────────────┐
   │ 每个文档块都被转换成向量                  │
   │ (HuggingFaceEmbeddings)                   │
   │                                          │
   │ "PHB titer 730 mg/L..."                  │
   │      ↓                                    │
   │ [0.123, -0.456, 0.789, ..., 0.234]      │ ← 384 维向量
   │      ↓                                    │
   │ 存储在 Chroma 向量数据库中                │
   └──────────────────────────────────────────┘
      ↓
   [Chroma Database] 
   ┌──────────────────────────────────────────┐
   │ 向量索引结构：                            │
   │ - 文档1向量 + 元数据 (page, source)      │
   │ - 文档2向量 + 元数据                      │
   │ - 文档3向量 + 元数据                      │
   │ - ...共 N 个文档向量                      │
   └──────────────────────────────────────────┘


【查询阶段】(在 batch_qa.py 中)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

   用户问题
   "What is the PHB titer in S. cerevisiae?"
      ↓
   ┌──────────────────────────────────────────────────────────┐
   │ 步骤 1: 问题向量化                                       │
   │ ============================================             │
   │ embeddings = HuggingFaceEmbeddings(                      │
   │     model_name="all-MiniLM-L6-v2"                       │
   │ )                                                        │
   │                                                          │
   │ question_vector = embeddings.embed_query(question_text)│
   │ # 结果: 384 维浮点数向量                                │
   │ # [0.115, -0.458, 0.792, ..., 0.239]                   │
   └──────────────────────────────────────────────────────────┘
      ↓
   ┌──────────────────────────────────────────────────────────┐
   │ 步骤 2: 相似度搜索                                       │
   │ ============================================             │
   │ docs_with_scores = db.similarity_search_with_score(    │
   │     question_text,                                      │
   │     k=3  # 返回前 3 个最相似的文档                      │
   │ )                                                        │
   │                                                          │
   │ 内部执行:                                               │
   │ for each doc_vector in database:                       │
   │     score = cosine_similarity(                          │
   │         question_vector,                               │
   │         doc_vector                                      │
   │     )                                                   │
   │ # 计算所有文档与问题的相似度                            │
   │                                                          │
   │ sorted_results = sort(scores)                           │
   │ return top_3_results_with_scores                        │
   └──────────────────────────────────────────────────────────┘
      ↓
   ┌──────────────────────────────────────────────────────────┐
   │ 步骤 3: 返回结果                                         │
   │ ============================================             │
   │ 返回值:                                                  │
   │ [                                                        │
   │   (Document1, 0.9572),  ← 第一相关文档，相似度 0.9572  │
   │   (Document2, 0.9272),  ← 第二相关文档，相似度 0.9272  │
   │   (Document3, 0.9073)   ← 第三相关文档，相似度 0.9073  │
   │ ]                                                        │
   └──────────────────────────────────────────────────────────┘
      ↓
   ┌──────────────────────────────────────────────────────────┐
   │ 步骤 4: 提取和保存                                       │
   │ ============================================             │
   │ sources = []                                             │
   │ for doc, score in docs_with_scores:                    │
   │     sources.append({                                    │
   │         "page": doc.metadata.get("page"),              │
   │         "source": doc.metadata.get("source"),          │
   │         "similarity_score": float(score)               │
   │     })                                                  │
   │                                                          │
   │ # 结果被保存到 JSON:                                     │
   │ {                                                        │
   │   "id": 1,                                              │
   │   "question": "What is the PHB titer...",              │
   │   "answer": "根据文档...",                              │
   │   "gold_answer": "730 mg/L",                            │
   │   "answer_correctness": true,                           │
   │   "sources": [                                          │
   │     {                                                   │
   │       "page": 12,                                       │
   │       "source": "source_documents/Le.pdf",             │
   │       "similarity_score": 0.9572  ← 实际分数！         │
   │     }                                                   │
   │   ]                                                      │
   │ }                                                        │
   └──────────────────────────────────────────────────────────┘


【技术细节：余弦相似度计算】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

余弦相似度公式:
   
   similarity(A, B) = (A · B) / (||A|| × ||B||)
   
其中:
   A · B = Σ(A[i] × B[i])  # 点积
   ||A|| = √(Σ(A[i]²))      # 向量范数（长度）
   ||B|| = √(Σ(B[i]²))      # 向量范数（长度）

示例计算 (假设 2 维简化):
   
   向量 A = [0.5, 0.2]      (问题的向量)
   向量 B = [0.51, 0.19]    (文档1的向量)
   向量 C = [0.1, 0.9]      (文档2的向量)
   
   A · B = 0.5×0.51 + 0.2×0.19 = 0.255 + 0.038 = 0.293
   ||A|| = √(0.5² + 0.2²) = √(0.25 + 0.04) = √0.29 ≈ 0.539
   ||B|| = √(0.51² + 0.19²) = √(0.2601 + 0.0361) = √0.2962 ≈ 0.544
   
   similarity(A, B) = 0.293 / (0.539 × 0.544) = 0.293 / 0.293 ≈ 1.0
   
   ✅ 向量 A 和 B 几乎相同，相似度接近 1.0


   A · C = 0.5×0.1 + 0.2×0.9 = 0.05 + 0.18 = 0.23
   ||C|| = √(0.1² + 0.9²) = √(0.01 + 0.81) = √0.82 ≈ 0.906
   
   similarity(A, C) = 0.23 / (0.539 × 0.906) ≈ 0.47
   
   ⚠️  向量 A 和 C 差异较大，相似度约 0.47


【为什么使用余弦相似度】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

优点:
✅ 只考虑方向，不考虑向量长度
   - "a very good document" 和 "good document" 的向量方向相似
   - 尽管长度不同，但相似度分数会很高
   
✅ 计算高效
   - 可以用向量化操作快速计算
   - Chroma 使用 HNSW 索引加速搜索
   
✅ 符合语义相似度
   - 相同含义的文本会产生相似方向的向量
   - 相差含义的文本会有不同方向的向量
   
✅ 输出范围合理 (0-1)
   - 0: 完全正交（无关）
   - 1: 完全平行（相同）
   - 0.5: 垂直角度（90°）


【代码级别的实现细节】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

1. Chroma 数据库内部:
   
   class Chroma(VectorStore):
       def similarity_search_with_score(self, query, k=3):
           # 步骤 1: 向量化查询
           query_embedding = self.embedding_function.embed_query(query)
           
           # 步骤 2: 搜索最相似的向量 (使用 HNSW 索引)
           results = self._index.search(
               query_embedding, 
               k=k,  # 返回 top-k 结果
               metric='cosine'  # 使用余弦相似度
           )
           
           # 步骤 3: 构造返回值
           docs_with_scores = []
           for document_id, score in results:
               doc = self._documents[document_id]
               docs_with_scores.append((doc, score))
           
           return docs_with_scores


2. 在我们的代码中:
   
   # 在 batch_qa.py 中
   docs_with_scores = db.similarity_search_with_score(
       question_text,  # 用户的问题
       k=3             # 返回前 3 个最相关的文档
   )
   
   for doc, score in docs_with_scores:
       sources.append({
           "page": doc.metadata.get("page"),
           "source": doc.metadata.get("source"),
           "similarity_score": float(score)  # 这就是相似度分数！
       })


【性能优化：HNSW 索引】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

问题: 如果数据库有 10,000+ 个文档，逐一计算相似度会很慢

解决方案: HNSW (Hierarchical Navigable Small World) 图索引

工作原理:
   ├─ 构建分层的向量导航图
   │  ├─ 最底层: 所有向量节点
   │  ├─ 中间层: 稀疏连接的关键节点
   │  └─ 顶层: 入口点
   │
   ├─ 查询时的遍历:
   │  1. 从顶层开始
   │  2. 在当前层找到最接近的邻居
   │  3. 向下一层遍历
   │  4. 最终在底层返回最相似的 k 个向量
   
复杂度:
   ✅ 暴力搜索: O(n) - 需要计算与所有文档的相似度
   ✅ HNSW 搜索: O(log n) - 只需遍历分层图


【实际分数示例】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

从我们的实际运行结果:

查询: "What is the PHB titer achieved by S. cerevisiae?"

结果1: 相似度 0.9572 ⭐⭐⭐⭐⭐
   内容: "Table 4. Comparison of PHA production..."
   解读: 极度相关，文档直接讨论了 PHB 和 S. cerevisiae

结果2: 相似度 0.9272 ⭐⭐⭐⭐
   内容: "252 mg/L under oxygen-limiting conditions..."
   解读: 非常相关，提供具体的产量数据

结果3: 相似度 0.9073 ⭐⭐⭐⭐
   内容: "issues in industrial-scale production..."
   解读: 相关但不是直接答案，提供背景信息

所有 3 个都是 > 0.90 的高分数，说明搜索效果很好！


【总结】
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

相似度分数 = 衡量查询与文档相关程度的指标

计算方法:
   1. 将文本转换为 384 维向量（使用 all-MiniLM-L6-v2 模型）
   2. 计算查询向量与所有文档向量的余弦相似度
   3. 返回分数最高的 k 个文档和对应分数

应用意义:
   ✅ 高分数 (> 0.8) → 强烈推荐用于生成答案
   ✅ 中等分数 (0.5-0.8) → 可以作为参考
   ✅ 低分数 (< 0.5) → 通常不相关，应忽略

在我们的 RAG 系统中:
   ✅ 分数直接影响答案质量
   ✅ 高分文档保证了答案的准确性
   ✅ 可以用来诊断系统性能
"""

print(ARCHITECTURE)

# 保存为文本文件
with open("similarity_explanation.txt", "w", encoding="utf-8") as f:
    f.write(ARCHITECTURE)

print("\n✅ 详细说明已保存到 similarity_explanation.txt")
